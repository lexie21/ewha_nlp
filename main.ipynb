{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageLayoutAnalysisLoader, ChatUpstage, UpstageEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from kobert_transformers import get_kobert_model, get_tokenizer\n",
    "from langdetect import detect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wikipediaapi\n",
    "import spacy\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "# set parameters\n",
    "api_key = \"up_Yvl9vhT0SfWFZRwucrXCW4O4th9IH\"\n",
    "data_path = \".\" # folder path containing ewah.pdf and samples.csv\n",
    "\n",
    "def parse_pdf():\n",
    "    layzer = UpstageLayoutAnalysisLoader(api_key=api_key,file_path=os.path.join(data_path, 'ewha.pdf'), output_type=\"text\")\n",
    "    pdf_text = layzer.load()  # or layzer.lazy_load()\n",
    "\n",
    "    # 2. Split\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, chunk_overlap=250\n",
    "    )\n",
    "    articles = text_splitter.split_documents(pdf_text)\n",
    "    return articles\n",
    "\n",
    "articles = parse_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_name, context_extraction_method, uses_wiki):\n",
    "    prompts, answers = read_file(file_name)\n",
    "    if(context_extraction_method == \"kobert\"):\n",
    "        contexts = find_context_kobert(prompts, articles, uses_wiki)\n",
    "    elif (context_extraction_method == \"upstage\"):\n",
    "        contexts = find_context_upstage(prompts, articles, uses_wiki)\n",
    "    else:\n",
    "        print(\"Invalid context extraction method\")\n",
    "    responses = get_llm_responses(prompts, contexts)\n",
    "    print_accuracy(responses, answers)\n",
    "\n",
    "def read_file(file_name):\n",
    "    data = pd.read_csv(os.path.join(data_path, file_name))\n",
    "    prompts = data['prompts']\n",
    "    answers = data['answers']\n",
    "    # returns three lists: prompts, answers and evidences\n",
    "    return prompts, answers\n",
    "\n",
    "# Cleans question by removing options\n",
    "def clean_question(question):\n",
    "    result = True\n",
    "    # Find the position of the first ')'\n",
    "    pos1 = question.find(')')\n",
    "    # Find the position of the first '(A)'\n",
    "    pos2 = question.find('(A)')\n",
    "    # Check if both positions were found\n",
    "    if pos1 != -1 and pos2 != -1 and pos1 < pos2:\n",
    "        # Extract content between the positions\n",
    "        question = question[pos1 + 1 : pos2].strip()\n",
    "    else:\n",
    "        print(\"Could not find the positions or invalid positions.\")\n",
    "        result = False\n",
    "    return question, result\n",
    "\n",
    "\n",
    "# Extract answer from a response\n",
    "def extract_answer(response):\n",
    "    \"\"\"\n",
    "    extracts the answer from the response using a regular expression.\n",
    "    expected format: \"(A)\"\n",
    "\n",
    "    if there are no answers formatted like the format, it returns None.\n",
    "    \"\"\"\n",
    "    pattern = r\"\\(([A-Z])\\)\"  # Regular expression to capture the answer letter\n",
    "    match = re.search(pattern, response)\n",
    "\n",
    "    if match:\n",
    "        return match.group() # Extract the letter inside parentheses (e.g., A)\n",
    "    else:\n",
    "        return extract_again(response)\n",
    "def extract_again(response):\n",
    "    pattern = r\"([A-Z])\"\n",
    "    match = re.search(pattern, response)\n",
    "    if match:\n",
    "        return f\"({match.group(0)})\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# prints responses\n",
    "def print_responses(responses, answers):\n",
    "    count = 0\n",
    "    for response in responses:\n",
    "        print(f\"Question {count+1} : {response} \\t Correct answer: {answers[count]}\")\n",
    "        count += 1\n",
    "\n",
    "# prints accuracy\n",
    "def print_accuracy(responses, answers):\n",
    "        \n",
    "    # Count the number of matching values at the same index\n",
    "    count = 0\n",
    "    index = 0\n",
    "    mistakes_index = []\n",
    "    for a, b in zip(responses, answers):\n",
    "        if extract_answer(a) == b:\n",
    "            count += 1\n",
    "        else:\n",
    "            mistakes_index.append(index)\n",
    "        index += 1\n",
    "    print(f\"Correct answers: {count}/{len(responses)} {count/len(responses)*100:.2f}% accuracy\")\n",
    "\n",
    "# Finds best contexts using upstage embedding\n",
    "def find_context_upstage(prompts, articles, uses_wiki):\n",
    "    embeddings = UpstageEmbeddings(\n",
    "        api_key=api_key,\n",
    "        model=\"embedding-query\"\n",
    "    )\n",
    "    # Compute document embeddings\n",
    "    doc_result = embeddings.embed_documents(\n",
    "        [article.page_content for article in articles]\n",
    "    )\n",
    "    contexts = []\n",
    "    count = 1\n",
    "    for prompt in prompts:\n",
    "        print(f\"Processing question {count}\")\n",
    "        count += 1\n",
    "        question, result = clean_question(prompt)\n",
    "        if detect(question) == \"en\":\n",
    "            if uses_wiki == False:\n",
    "                contexts.append([])\n",
    "                continue\n",
    "            else:\n",
    "                contexts.append(get_contexts_wiki(question))\n",
    "                continue\n",
    "        query_result = embeddings.embed_query(question)\n",
    "        similarity_list = []\n",
    "        for passage_embedding in doc_result:\n",
    "            similarity = np.dot(passage_embedding, query_result)\n",
    "            similarity_list.append(similarity)\n",
    "            \n",
    "        values = similarity_list\n",
    "        # Get the indexes sorted by values in descending order\n",
    "        sorted_indexes = sorted(range(len(values)), key=lambda i: values[i], reverse=True)\n",
    "\n",
    "        # Take top 3 chunks as context\n",
    "        context = []\n",
    "        for i in range(10):\n",
    "            context.append(articles[sorted_indexes[i]].page_content)\n",
    "        contexts.append(context)\n",
    "    return contexts\n",
    "\n",
    "# Finds best context using KoBERT\n",
    "def find_context_kobert(prompts, articles, uses_wiki):\n",
    "    # Load KoBERT tokenizer and model\n",
    "    tokenizer = get_tokenizer()\n",
    "    model = get_kobert_model()\n",
    "    def embed_text(text, tokenizer, model):\n",
    "        # Embeds text using KoBERT.\n",
    "        # Tokenize input\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        # Get model outputs\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        # Mean-pool embeddings\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        return embeddings\n",
    "    # Embed articles\n",
    "    article_embeddings = torch.vstack([embed_text(article.page_content, tokenizer, model) for article in articles])\n",
    "    contexts = []\n",
    "    count = 1\n",
    "    for prompt in prompts:\n",
    "        print(f\"Processing question {count}\")\n",
    "        count += 1\n",
    "        # Embed question\n",
    "        question, result = clean_question(prompt)\n",
    "        if detect(question) == \"en\":\n",
    "            if uses_wiki == False:\n",
    "                contexts.append([])\n",
    "                continue\n",
    "            else:\n",
    "                contexts.append(get_contexts_wiki(question))\n",
    "                continue\n",
    "        question_embedding = embed_text(question, tokenizer, model)\n",
    "        # Compute cosine similarity between question and articles\n",
    "        cosine_sim = torch.nn.functional.cosine_similarity(article_embeddings, question_embedding)\n",
    "        # Find the top 3 most relevant articles\n",
    "        values = cosine_sim\n",
    "        # Get the indexes sorted by values in descending order\n",
    "        sorted_indexes = sorted(range(len(values)), key=lambda i: values[i], reverse=True)\n",
    "        # Take top 3 chunks as context\n",
    "        context = [articles[sorted_indexes[0]].page_content, articles[sorted_indexes[1]].page_content, articles[sorted_indexes[2]].page_content]\n",
    "        contexts.append(context)\n",
    "    return contexts\n",
    "\n",
    "def get_contexts_wiki(question):\n",
    "    # Create a Wikipedia API instance\n",
    "    wiki = wikipediaapi.Wikipedia(\"NLP Project (yanrenyu00@gmail.com)\", \"en\")\n",
    "    # Extract keywords from question\n",
    "    keywords = extract_keywords(question)\n",
    "    context = []\n",
    "    for keyword in keywords:\n",
    "        page = wiki.page(keyword)\n",
    "        # Check if the page exists\n",
    "        if page.exists():\n",
    "            context.append(page.summary)\n",
    "        else:\n",
    "            # print(f\"Page does not exist for {keyword}\")\n",
    "            pass\n",
    "    return context\n",
    "\n",
    "\n",
    "# Extract keywords of an english question\n",
    "def extract_keywords(question):\n",
    "    # Load spaCy's English model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    # Process the question\n",
    "    doc = nlp(question)\n",
    "    # Extract nouns, proper nouns, and compound nouns\n",
    "    keywords = [chunk.text for chunk in doc.noun_chunks]\n",
    "    return keywords\n",
    "\n",
    "def get_llm_responses(prompts, contexts):\n",
    "    llm = ChatUpstage(api_key = api_key, model=\"solar-1-mini-chat\")\n",
    "    prompt_template = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an expert in multiple domains, including Law, Psychology, Business, Philosophy, and History. \n",
    "        Your task is to provide the most accurate answer to the given question based on the provided context. \n",
    "        Follow these instructions carefully:\n",
    "\n",
    "        1. Read the question and context carefully.\n",
    "        2. Your task is to **select the letter of the correct option**. \n",
    "        3. If the correct answer is a combination of choices (e.g., \"x and y\"), **explicitly select the combined option** (e.g., (D): \"x and y\") rather than any single choice (e.g., (A): \"x\" or (B): \"y\").\n",
    "        4. **Avoid assuming single choices are correct if a combination option matches all criteria**.\n",
    "        5. If the correct answer is not explicitly available in the context, use your judgment to choose the most plausible answer.\n",
    "        6. Your final answer should be in the form of the letter corresponding to the answer (e.g., (A), (B), (C), etc.).\n",
    "\n",
    "        I have provided 2 examples:\n",
    "\n",
    "        Example:\n",
    "        Question: Who likes to eat chips?    \n",
    "        (A): Ha  \n",
    "        (B): Lam  \n",
    "        (C): Bun  \n",
    "        (D): All of the above  \n",
    "        Context: Ha, Lam, Bun like to eat chips.\n",
    "        Answer: (D) \n",
    "\n",
    "        Example :\n",
    "        Question : Which Team won the game?\n",
    "        (A)B\n",
    "        (B)C\n",
    "        (C)A\n",
    "        Context : Team B won the game.\n",
    "        Answer: (A)\n",
    "\n",
    "\n",
    "        The answer must look like this always!  \n",
    "        Answer: (<answer>) where <answer> is a single capital letter\n",
    "\n",
    "        ---\n",
    "\n",
    "        ### For Business-related questions that involve calculations (e.g., averages, standard deviations):\n",
    "\n",
    "        1. If the question involves calculating an average or standard deviation, first follow these steps:\n",
    "\n",
    "        - **To calculate the average (mean):**\n",
    "        1. Add up all the values in the dataset.\n",
    "        2. Divide the total sum by the number of values.\n",
    "     \n",
    "        - **To calculate the standard deviation:**\n",
    "        1. Find the average (mean) of the dataset.\n",
    "        2. Subtract the average from each data point and square the result.\n",
    "        3. Calculate the average of these squared differences.\n",
    "        4. Take the square root of this average to get the standard deviation.\n",
    "\n",
    "        2. Once you have the correct result, select the corresponding answer from the options.\n",
    "\n",
    "        ---\n",
    "\n",
    "        ### Prompt Format:\n",
    "\n",
    "        Question: {question}  \n",
    "        Context: {context}  \n",
    "        Answer: (<answer>)\n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "    chain = prompt_template | llm\n",
    "    responses = []\n",
    "    count = 0\n",
    "    for prompt in prompts:\n",
    "        # print(f\"Prompt: {prompt}\")\n",
    "        response = chain.invoke({\"question\": prompt, \"context\": \"\\n\".join(contexts[count])})\n",
    "        # print(f\"Response: {response.content}\")\n",
    "        responses.append(response.content)\n",
    "        count += 1\n",
    "        time.sleep(0) # Increase delay if API rate limits are hit\n",
    "    return responses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with file name to run\n",
    "# Available context extraction methods: upstage/kobert (only applicable for ewha questions)\n",
    "main(file_name = \"testsets/test_sample_MMLU_hard.csv\", context_extraction_method = \"upstage\", uses_wiki = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
